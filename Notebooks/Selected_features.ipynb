{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Add the ./src folder to the Python module search path\n",
    "sys.path.append(os.path.join(current_dir, '..', 'src'))\n",
    "\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data/'\n",
    "\n",
    "features_file_1 = 'featureSelection/selection_cleanMordredDescriptors.csv'\n",
    "features_file_1_normalized = 'featureSelection/selection_cleanMordredDescriptorsNormalized.csv'\n",
    "\n",
    "features_file_2 =  'deepnose_features.npy'\n",
    "CID_file = 'molecules_train_cid.npy'\n",
    "\n",
    "# Read all copies, before and after correction; before was also downloaded from Dropbox.\n",
    "mixture_file = 'Mixure_Definitions_Training_set.csv' \n",
    "training_task_file = 'TrainingData_mixturedist.csv'\n",
    "\n",
    "# Mordred features\n",
    "features_1 = pd.read_csv(os.path.join(input_path, features_file_1), index_col= 0)\n",
    "features_1_normalized = pd.read_csv(os.path.join(input_path, features_file_1), index_col= 0)\n",
    "\n",
    "features_2 = np.load(os.path.join(input_path, features_file_2))\n",
    "\n",
    "features_CIDs = np.load(os.path.join(input_path, CID_file))\n",
    "\n",
    "# Training dataframe\n",
    "training_set = pd.read_csv(os.path.join(input_path, training_task_file))\n",
    "\n",
    "# Mapping helper files\n",
    "mixtures_IDs = pd.read_csv(os.path.join(input_path, mixture_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 70)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nAcid</th>\n",
       "      <th>AATS6dv</th>\n",
       "      <th>ATSC3c</th>\n",
       "      <th>ATSC8c</th>\n",
       "      <th>ATSC0Z</th>\n",
       "      <th>ATSC7i</th>\n",
       "      <th>AATSC5c</th>\n",
       "      <th>AATSC1s</th>\n",
       "      <th>AATSC4Z</th>\n",
       "      <th>AATSC5Z</th>\n",
       "      <th>...</th>\n",
       "      <th>n8FHRing</th>\n",
       "      <th>nG12FHRing</th>\n",
       "      <th>n8FARing</th>\n",
       "      <th>n9FARing</th>\n",
       "      <th>n11FARing</th>\n",
       "      <th>nG12FARing</th>\n",
       "      <th>n8FAHRing</th>\n",
       "      <th>n9FAHRing</th>\n",
       "      <th>nG12FAHRing</th>\n",
       "      <th>GGI10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.234011</td>\n",
       "      <td>-0.141658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.330733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043811</td>\n",
       "      <td>-1.326389</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-12.297603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.234011</td>\n",
       "      <td>-0.018407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.055505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043811</td>\n",
       "      <td>-0.003401</td>\n",
       "      <td>-47.175154</td>\n",
       "      <td>-12.297603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.234011</td>\n",
       "      <td>0.115591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.748652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>-0.572650</td>\n",
       "      <td>-4.302041</td>\n",
       "      <td>5.897959</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.234011</td>\n",
       "      <td>-0.056973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.325456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043811</td>\n",
       "      <td>-0.197037</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>-12.297603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.584967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     nAcid   AATS6dv    ATSC3c  ATSC8c    ATSC0Z  ATSC7i   AATSC5c   AATSC1s  \\\n",
       "CID                                                                            \n",
       "176      1 -1.234011 -0.141658     0.0  4.330733     0.0 -0.043811 -1.326389   \n",
       "177      0 -1.234011 -0.018407     0.0  4.055505     0.0 -0.043811 -0.003401   \n",
       "179      0 -1.234011  0.115591     0.0  4.748652     0.0  0.002252 -0.572650   \n",
       "180      0 -1.234011 -0.056973     0.0  4.325456     0.0 -0.043811 -0.197037   \n",
       "240      0  0.000000  0.014268     0.0  4.584967     0.0  0.000605 -0.004535   \n",
       "\n",
       "       AATSC4Z    AATSC5Z  ...  n8FHRing  nG12FHRing  n8FARing  n9FARing  \\\n",
       "CID                        ...                                             \n",
       "176   9.000000 -12.297603  ...         0           0         0         0   \n",
       "177 -47.175154 -12.297603  ...         0           0         0         0   \n",
       "179  -4.302041   5.897959  ...         0           0         0         0   \n",
       "180   4.840000 -12.297603  ...         0           0         0         0   \n",
       "240  -0.200000   0.888889  ...         0           0         0         0   \n",
       "\n",
       "     n11FARing  nG12FARing  n8FAHRing  n9FAHRing  nG12FAHRing  GGI10  \n",
       "CID                                                                   \n",
       "176          0           0          0          0            0    0.0  \n",
       "177          0           0          0          0            0    0.0  \n",
       "179          0           0          0          0            0    0.0  \n",
       "180          0           0          0          0            0    0.0  \n",
       "240          0           0          0          0            0    0.0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "# standardize Mordred\n",
    "features_1 = scaler.fit_transform(features_1)\n",
    "features_1_normalized = features_1_normalized.to_numpy()\n",
    "\n",
    "# log standardize deepnose\n",
    "epsilon = 1e-8 \n",
    "features_2 = scaler.fit_transform(np.log(features_2 + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check the number of unique non-NaN values in each feature column\n",
    "num_unique_values = np.count_nonzero(~np.isnan(features_1), axis=0)\n",
    "\n",
    "# Print if the number of unique non-NaN values for each feature\n",
    "for i, count in enumerate(num_unique_values):\n",
    "    if count == 0:\n",
    "        print(f\"Feature {i}: {count} unique non-NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map CID to features:\n",
    "CID2features_mordred =  {CID: features_1[i] for i, CID in enumerate(features_CIDs)}\n",
    "CID2features_deepnose=  {CID: features_2[i] for i, CID in enumerate(features_CIDs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_m, y, num_mixtures, all_pairs_CIDs = format_Xy(training_set,  mixtures_IDs, CID2features_mordred, method = 'avg')\n",
    "X_d, _, _, _ = format_Xy(training_set,  mixtures_IDs, CID2features_deepnose, method = 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input pairs to a suitable format for training\n",
    "X_pairs_m = np.array([(np.concatenate((x1, x2))) for x1, x2 in X_m])\n",
    "X_pairs_d = np.array([(np.concatenate((x1, x2))) for x1, x2 in X_d])\n",
    "\n",
    "y_true = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_m = [get_euclidean_distance(m[0], m[1]) for m in X_m]\n",
    "similarities_m = [get_cosine_similarity(m[0], m[1]) for m in X_m]\n",
    "angles_m = [get_cosine_angle(m[0], m[1]) for m in X_m] \n",
    "\n",
    "distances_d = [get_euclidean_distance(m[0], m[1]) for m in X_d]\n",
    "similarities_d = [get_cosine_similarity(m[0], m[1]) for m in X_d]\n",
    "angles_d = [get_cosine_angle(m[0], m[1]) for m in X_d] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_monos = [ len( set(pair[0]).intersection(set(pair[1]))) for pair in all_pairs_CIDs]\n",
    "diff_monos = [ len( set(pair[0]).difference(set(pair[1]))) for pair in all_pairs_CIDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['Sum num monos'] = np.array(num_mixtures).sum(axis = 1)\n",
    "training_set['Shared'] = shared_monos\n",
    "training_set['Diff'] = diff_monos\n",
    "training_set['Num mixture1'] = np.array(num_mixtures)[:, 0]\n",
    "training_set['Num mixture2'] = np.array(num_mixtures)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = training_set['Dataset'].to_numpy()\n",
    "encoder = OneHotEncoder()\n",
    "data_arr = encoder.fit_transform(datasets.reshape(-1, 1))\n",
    "data_arr = data_arr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add all information above\n",
    "X_features = np.hstack( (X_pairs_d, X_pairs_m,\n",
    "                        np.array(distances_m).reshape(500, 1), \n",
    "                        np.array(similarities_m).reshape(500, 1), \n",
    "                        np.array(angles_m).reshape(500, 1), \n",
    "                        np.array(distances_d).reshape(500, 1), \n",
    "                        np.array(similarities_d).reshape(500, 1), \n",
    "                        np.array(angles_d).reshape(500, 1), \n",
    "                        np.array(shared_monos).reshape(500, 1), \n",
    "                        np.array(diff_monos).reshape(500, 1), \n",
    "                        np.array(num_mixtures).reshape(500,2), \n",
    "                        data_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R (Deepnose embedding Eucledian distance v.s Experimental Value):  0.2833580961355149\n"
     ]
    }
   ],
   "source": [
    "# dist_corr = np.corrcoef(distances_d, y_true)[0, 1]\n",
    "dist_corr = np.corrcoef(distances_m, y_true)[0, 1]\n",
    "\n",
    "print('R (Deepnose embedding Eucledian distance v.s Experimental Value): ', dist_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R (Cosyne similarity v.s. Experimental Value):  -0.39810902195331255\n"
     ]
    }
   ],
   "source": [
    "# sim_corr = np.corrcoef(similarities_d, y_true)[0, 1]\n",
    "sim_corr = np.corrcoef(similarities_m, y_true)[0, 1]\n",
    "\n",
    "print('R (Cosyne similarity v.s. Experimental Value): ', sim_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R (Vector angle v.s. Experimental Value):  0.4219668406899492\n"
     ]
    }
   ],
   "source": [
    "# sim_corr = np.corrcoef(angles_d, y_true)[0, 1]\n",
    "sim_corr = np.corrcoef(angles_m, y_true)[0, 1]\n",
    "\n",
    "print('R (Vector angle v.s. Experimental Value): ', sim_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "seed = 314159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_list = []\n",
    "xgb_pred_list = []\n",
    "kf_rf_importances = []\n",
    "y_true_list = []\n",
    "test_indices_list = []  # Keep track of the test indices in each fold\n",
    "\n",
    "# Perform k-fold cross-validation:\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "for train_index, test_index in kf.split(X_features):\n",
    "    X_train, X_test = X_features[train_index], X_features[test_index]\n",
    "    y_train, y_test = y_true[train_index], y_true[test_index]\n",
    "    \n",
    "    # Train the Random Forest regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=seed)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Train the XGBoost regressor\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=seed)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions \n",
    "    rf_pred = rf.predict(X_test)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Get the feature importances\n",
    "    importances = rf.feature_importances_\n",
    "    kf_rf_importances.append(importances)\n",
    "    rf_pred_list.extend(rf_pred)\n",
    "    xgb_pred_list.extend(xgb_pred)\n",
    "    y_true_list.extend(y_test)\n",
    "    test_indices_list.extend(test_index)  # Store the test indices\n",
    "\n",
    "# Store the predictions and actual values\n",
    "results_df = pd.DataFrame({\n",
    "    'test_index': test_indices_list,\n",
    "    'rf_pred': rf_pred_list,\n",
    "    'xgb_pred': xgb_pred_list,\n",
    "    'y_true': y_true_list\n",
    "})\n",
    "\n",
    "# Merge the results with the training_set df\n",
    "training_set = training_set.merge(results_df, left_index=True, right_on='test_index')\n",
    "training_set.drop('test_index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mixture 1</th>\n",
       "      <th>Mixture 2</th>\n",
       "      <th>Experimental Values</th>\n",
       "      <th>Sum num monos</th>\n",
       "      <th>Shared</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Num mixture1</th>\n",
       "      <th>Num mixture2</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.557607</td>\n",
       "      <td>0.559192</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.649153</td>\n",
       "      <td>0.679491</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.496933</td>\n",
       "      <td>0.444451</td>\n",
       "      <td>0.505208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.411458</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.513710</td>\n",
       "      <td>0.435847</td>\n",
       "      <td>0.411458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.552296</td>\n",
       "      <td>0.601150</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset  Mixture 1  Mixture 2  Experimental Values  Sum num monos  \\\n",
       "150  Snitz 1          1          2             0.604167             20   \n",
       "300  Snitz 1          1          3             0.651042             11   \n",
       "0    Snitz 1          1          5             0.505208             40   \n",
       "1    Snitz 1          1          6             0.411458             50   \n",
       "50   Snitz 1          1          7             0.562500             14   \n",
       "\n",
       "     Shared  Diff  Num mixture1  Num mixture2   rf_pred  xgb_pred    y_true  \n",
       "150       0    10            10            10  0.557607  0.559192  0.604167  \n",
       "300       0    10            10             1  0.649153  0.679491  0.651042  \n",
       "0         0    10            10            30  0.496933  0.444451  0.505208  \n",
       "1         0    10            10            40  0.513710  0.435847  0.411458  \n",
       "50        0    10            10             4  0.552296  0.601150  0.562500  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - R: 0.617\n",
      "Random Forest - RMSE: 0.124\n",
      "\n",
      "XGBoost - R: 0.564\n",
      "XGBoost - RMSE: 0.131\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation and R^2 for Random Forest\n",
    "rf_corr = np.corrcoef(rf_pred_list, y_true_list)[0, 1]\n",
    "rf_rmse = np.sqrt(mean_squared_error(np.array(y_true_list), np.array(rf_pred_list)))\n",
    "\n",
    "print(f\"Random Forest - R: {rf_corr:.3f}\")\n",
    "print(f\"Random Forest - RMSE: {rf_rmse:.3f}\")\n",
    "print()\n",
    "# Calculate the correlation and R^2 for XGBoost\n",
    "xgb_corr = np.corrcoef(xgb_pred_list, y_true_list)[0, 1]\n",
    "xgb_rmse = np.sqrt(mean_squared_error(np.array(y_true_list), np.array(xgb_pred_list)))\n",
    "\n",
    "print(f\"XGBoost - R: {xgb_corr:.3f}\")\n",
    "print(f\"XGBoost - RMSE: {xgb_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feedback",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
