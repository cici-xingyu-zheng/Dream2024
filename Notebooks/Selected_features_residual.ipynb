{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Add the ./src folder to the Python module search path\n",
    "sys.path.append(os.path.join(current_dir, '..', 'src'))\n",
    "\n",
    "from train_test import *\n",
    "from utils import *\n",
    "from optimize import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge \n",
    "import xgboost as xgb\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data/'\n",
    "\n",
    "features_file_1 = 'featureSelection/selection_cleanMordredDescriptors.csv'\n",
    "features_file_2 =  'deepnose_features.npy'\n",
    "CID_file = 'molecules_train_cid.npy'\n",
    "\n",
    "# Read all copies, before and after correction; before was also downloaded from Dropbox.\n",
    "mixture_file = 'Mixure_Definitions_Training_set_UPD2.csv' \n",
    "training_task_file = 'TrainingData_mixturedist.csv'\n",
    "\n",
    "# Mordred features\n",
    "features_1 = pd.read_csv(os.path.join(input_path, features_file_1), index_col= 0)\n",
    "\n",
    "features_2 = np.load(os.path.join(input_path, features_file_2))\n",
    "\n",
    "features_CIDs = np.load(os.path.join(input_path, CID_file))\n",
    "# Training dataframe\n",
    "training_set = pd.read_csv(os.path.join(input_path, training_task_file))\n",
    "\n",
    "# Mapping helper files\n",
    "mixtures_IDs = pd.read_csv(os.path.join(input_path, mixture_file))\n",
    "\n",
    "\n",
    "feature_file_3 = 'Fingerprints/Morgan_Fingerprints_Frequency_Size50.csv'\n",
    "features_3 = pd.read_csv(os.path.join(input_path, feature_file_3), index_col= 0)\n",
    "features_file_4 =  'leffingwell_features_96.npy'\n",
    "features_4 = np.load(os.path.join(input_path, features_file_4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "# standardize Mordred\n",
    "features_1_np = scaler.fit_transform(features_1)\n",
    "features_1 = pd.DataFrame(features_1_np, columns=features_1.columns, index=features_1.index)\n",
    "\n",
    "\n",
    "# log standardize deepnose\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "epsilon = 1e-8 \n",
    "features_2 = scaler.fit_transform(np.log(features_2 + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check the number of unique non-NaN values in each feature column\n",
    "num_unique_values = np.count_nonzero(~np.isnan(features_1), axis=0)\n",
    "\n",
    "# Print if the number of unique non-NaN values for each feature\n",
    "for i, count in enumerate(num_unique_values):\n",
    "    if count == 0:\n",
    "        print(f\"Feature {i}: {count} unique non-NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map CID to features:\n",
    "\n",
    "# Dense\n",
    "CID2features_deepnose=  {CID: features_2[i] for i, CID in enumerate(features_CIDs)}\n",
    "CID2features_mordred =  {CID: features_1.loc[CID].tolist() for CID in features_CIDs}\n",
    "\n",
    "# Sparse\n",
    "CID2features_morgan =  {CID: features_3.loc[CID].tolist() for CID in features_CIDs}\n",
    "CID2features_leffingwell = {CID: features_4[i] for i, CID in enumerate(features_CIDs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make X_feature and y\n",
    "features_list = [CID2features_mordred, CID2features_deepnose]\n",
    "features_list_sparse = [CID2features_morgan, CID2features_leffingwell]\n",
    "\n",
    "X_dense, y_true = stacking_X_features(features_list, \"avg\")\n",
    "X_sparse, _ = stacking_X_features(features_list_sparse, \"sum\")\n",
    "\n",
    "X_dense_new, y_test_true = stacking_X_test_features(features_list,  X_dense, \"avg\")\n",
    "X_sparse_new, _ = stacking_X_test_features(features_list_sparse,  X_sparse, \"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with sparse, dense and meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "seed = 314159\n",
    "\n",
    "best_rf_dense = {'n_estimators': 500, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
    "best_rf_sparse = {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 0.5, 'max_depth': 30, 'bootstrap': True}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sequential residual training\n",
    "\n",
    "Train a sparse model over the residual of the best dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Performance (Residual Approach):\n",
      "Dense Model Performance: {'RMSE': 0.12248608448322859, 'Correlation': 0.6414345447059586}\n",
      "Sparse Model Performance (on residuals): {'RMSE': 0.5876211745488226, 'Correlation': 0.5100612998906364}\n",
      "Combined Model Performance: {'RMSE': 0.12050644047109231, 'Correlation': 0.6448345407631964}\n"
     ]
    }
   ],
   "source": [
    "def residual_ensemble_cv(X_dense, X_sparse, y, base_model_dense, base_model_sparse, n_folds=10):\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=314159)\n",
    "    \n",
    "    dense_preds = np.zeros(len(y))\n",
    "    sparse_preds = np.zeros(len(y))\n",
    "    combined_preds = np.zeros(len(y))\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_dense):\n",
    "        X_dense_train, X_dense_val = X_dense[train_index], X_dense[val_index]\n",
    "        X_sparse_train, X_sparse_val = X_sparse[train_index], X_sparse[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        # Train and predict with dense model\n",
    "        base_model_dense.fit(X_dense_train, y_train)\n",
    "        dense_preds[val_index] = base_model_dense.predict(X_dense_val)\n",
    "        \n",
    "        # Calculate residuals\n",
    "        train_residuals = y_train - base_model_dense.predict(X_dense_train)\n",
    "        \n",
    "        # Train sparse model on residuals\n",
    "        base_model_sparse.fit(X_sparse_train, train_residuals)\n",
    "        sparse_preds[val_index] = base_model_sparse.predict(X_sparse_val)\n",
    "        \n",
    "        # Combined prediction\n",
    "        combined_preds[val_index] = dense_preds[val_index] + sparse_preds[val_index]\n",
    "    \n",
    "    # Evaluate models\n",
    "    dense_rmse = np.sqrt(mean_squared_error(y, dense_preds))\n",
    "    dense_corr, _ = pearsonr(y, dense_preds)\n",
    "    sparse_rmse = np.sqrt(mean_squared_error(y-dense_preds, sparse_preds))\n",
    "    sparse_corr, _ = pearsonr(y, sparse_preds)\n",
    "    combined_rmse = np.sqrt(mean_squared_error(y, combined_preds))\n",
    "    combined_corr, _ = pearsonr(y, combined_preds)\n",
    "    \n",
    "    return {\n",
    "        'performance': {\n",
    "            'dense_model': {'RMSE': dense_rmse, 'Correlation': dense_corr},\n",
    "            'sparse_model (residuals)': {'RMSE': sparse_rmse, 'Correlation': sparse_corr},\n",
    "            'combined_model': {'RMSE': combined_rmse, 'Correlation': combined_corr}\n",
    "        }\n",
    "    }\n",
    "\n",
    "base_model_dense = RandomForestRegressor(**best_rf_dense, random_state=314159)\n",
    "base_model_sparse = RandomForestRegressor(**best_rf_sparse, random_state=314159)\n",
    "\n",
    "cv_results_residual = residual_ensemble_cv(X_dense, X_sparse, y_true, base_model_dense, base_model_sparse)\n",
    "\n",
    "print(\"Cross-validation Performance (Residual Approach):\")\n",
    "print(\"Dense Model Performance:\", cv_results_residual['performance']['dense_model'])\n",
    "print(\"Sparse Model Performance (on residuals):\", cv_results_residual['performance']['sparse_model (residuals)'])\n",
    "print(\"Combined Model Performance:\", cv_results_residual['performance']['combined_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_residual_models(X_dense, X_sparse, y, base_model_dense_class, base_model_sparse_class, n_models=10):\n",
    "    final_models = []\n",
    "    \n",
    "    for seed in range(n_models):\n",
    "        base_model_dense = base_model_dense_class(**best_rf_dense, random_state=seed)\n",
    "        base_model_sparse = base_model_sparse_class(**best_rf_sparse, random_state=seed)\n",
    "        \n",
    "        # Train dense model\n",
    "        final_base_model_dense = base_model_dense.fit(X_dense, y)\n",
    "        \n",
    "        # Calculate residuals\n",
    "        dense_predictions = final_base_model_dense.predict(X_dense)\n",
    "        residuals = y - dense_predictions\n",
    "        \n",
    "        # Train sparse model on residuals\n",
    "        final_base_model_sparse = base_model_sparse.fit(X_sparse, residuals)\n",
    "        \n",
    "        final_models.append((final_base_model_dense, final_base_model_sparse))\n",
    "    \n",
    "    return final_models\n",
    "\n",
    "def predict_residual_ensemble(X_dense_new, X_sparse_new, final_models):\n",
    "    dense_predictions = []\n",
    "    sparse_predictions = []\n",
    "    combined_predictions = []\n",
    "    \n",
    "    for dense_model, sparse_model in final_models:\n",
    "        dense_pred = dense_model.predict(X_dense_new)\n",
    "        sparse_pred = sparse_model.predict(X_sparse_new)\n",
    "        \n",
    "        dense_predictions.append(dense_pred)\n",
    "        sparse_predictions.append(sparse_pred)\n",
    "        \n",
    "        combined_pred = dense_pred + sparse_pred\n",
    "        combined_predictions.append(combined_pred)\n",
    "    \n",
    "    mean_dense_pred = np.mean(dense_predictions, axis=0)\n",
    "    mean_sparse_pred = np.mean(sparse_predictions, axis=0)\n",
    "    mean_combined_pred = np.mean(combined_predictions, axis=0)\n",
    "    \n",
    "    return {\n",
    "        'dense_prediction': mean_dense_pred,\n",
    "        'sparse_prediction': mean_sparse_pred,\n",
    "        'combined_prediction': mean_combined_pred\n",
    "    }\n",
    "\n",
    "final_models = train_final_residual_models(X_dense, X_sparse, y_true, RandomForestRegressor, RandomForestRegressor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'performance': {'dense_model': {'RMSE': 0.11981374609469903, 'Correlation': 0.7236704364028862}, 'sparse_model (residuals)': {'RMSE': 0.11682718231230123, 'Correlation': 0.5848251558597222}, 'combined_model': {'RMSE': 0.11682718231230123, 'Correlation': 0.7233837879784443}}}\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new data\n",
    "predictions = predict_residual_ensemble(X_dense_new, X_sparse_new, final_models)\n",
    "\n",
    "# Access predictions\n",
    "dense_preds = predictions['dense_prediction']\n",
    "sparse_preds = predictions['sparse_prediction']\n",
    "combined_preds = predictions['combined_prediction']\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate models\n",
    "dense_rmse = np.sqrt(mean_squared_error(y_test_true, dense_preds))\n",
    "dense_corr, _ = pearsonr(y_test_true, dense_preds)\n",
    "sparse_rmse = np.sqrt(mean_squared_error(y_test_true-dense_preds, sparse_preds))\n",
    "sparse_corr, _ = pearsonr(y_test_true-dense_preds, sparse_preds)\n",
    "combined_rmse = np.sqrt(mean_squared_error(y_test_true, combined_preds))\n",
    "combined_corr, _ = pearsonr(y_test_true, combined_preds)\n",
    "\n",
    "print( {\n",
    "    'performance': {\n",
    "        'dense_model': {'RMSE': dense_rmse, 'Correlation': dense_corr},\n",
    "        'sparse_model (residuals)': {'RMSE': sparse_rmse, 'Correlation': sparse_corr},\n",
    "        'combined_model': {'RMSE': combined_rmse, 'Correlation': combined_corr}\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feedback",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
