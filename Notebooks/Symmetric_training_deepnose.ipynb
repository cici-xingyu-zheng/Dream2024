{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Add the ./src folder to the Python module search path\n",
    "sys.path.append(os.path.join(current_dir, '..', 'src'))\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Read and inspect data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data'\n",
    "\n",
    "feature_file = 'deepnose_features_UPD.npy'\n",
    "CID_file = 'molecules_train_cid.npy'\n",
    "\n",
    "mixture_file = 'Mixure_Definitions_Training_set.csv'\n",
    "training_task_file = 'TrainingData_mixturedist.csv'\n",
    "\n",
    "# Deepnose features\n",
    "features = np.load(os.path.join(input_path, feature_file))\n",
    "# Training dataframe\n",
    "training_set = pd.read_csv(os.path.join(input_path, training_task_file))\n",
    "\n",
    "# Mapping helper files\n",
    "mixtures_IDs = pd.read_csv(os.path.join(input_path, mixture_file))\n",
    "features_CIDs = np.load(os.path.join(input_path, CID_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out log standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiation\n",
    "# features = np.exp(features)\n",
    "# Standard transform features:\n",
    "epsilon = 1e-8\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "features = scaler.fit_transform(np.log(features + epsilon))\n",
    "\n",
    "# Map CID to 96 dim features:\n",
    "CID2features =  {CID: features[i] for i, CID in enumerate(features_CIDs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- each `x` in `X` contains a two vector tuple `(mixture_1, mixture_2)`, index ordered same way as `training_set`\n",
    "- `method` specifies the ways to create the mixture embeeding from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, num_mixtures, all_pairs_CIDs = format_Xy(training_set,  mixtures_IDs, CID2features, method = 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input pairs to a suitable format for training\n",
    "X_pairs_1 = np.array([(np.concatenate((x1, x2))) for x1, x2 in X])\n",
    "X_pairs_2 = np.array([(np.concatenate((x1, x2))) for x2, x1 in X])\n",
    "\n",
    "y_true = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [get_euclidean_distance(m[0], m[1]) for m in X]\n",
    "similarities = [get_cosine_similarity(m[0], m[1]) for m in X]\n",
    "angles = [get_cosine_angle(m[0], m[1]) for m in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_monos = [ len( set(pair[0]).intersection(set(pair[1]))) for pair in all_pairs_CIDs]\n",
    "diff_monos = [ len( set(pair[0]).difference(set(pair[1]))) for pair in all_pairs_CIDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = training_set['Dataset'].to_numpy()\n",
    "# Returns the uniques in the order of appearance\n",
    "desired_order = training_set['Dataset'].unique().tolist() \n",
    "encoder = OneHotEncoder(categories=[desired_order])\n",
    "data_arr = encoder.fit_transform(datasets.reshape(-1, 1))\n",
    "data_arr = data_arr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add all information above\n",
    "X_features_1 = np.hstack((X_pairs_1, np.array(distances).reshape(500, 1), \n",
    "                        np.array(similarities).reshape(500, 1), \n",
    "                        np.array(angles).reshape(500, 1), \n",
    "                        np.array(shared_monos).reshape(500, 1), \n",
    "                        np.array(diff_monos).reshape(500, 1), \n",
    "                        np.array(num_mixtures), \n",
    "                        data_arr))\n",
    "X_features_2 = np.hstack((X_pairs_2, np.array(distances).reshape(500, 1), \n",
    "                        np.array(similarities).reshape(500, 1), \n",
    "                        np.array(angles).reshape(500, 1), \n",
    "                        np.array(shared_monos).reshape(500, 1), \n",
    "                        np.array(diff_monos).reshape(500, 1), \n",
    "                        np.array(num_mixtures), \n",
    "                        data_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = np.empty((1000, X_features_1.shape[1]), dtype=X_features_1.dtype)\n",
    "X_features[0::2] = X_features_1\n",
    "X_features[1::2] = X_features_2\n",
    "\n",
    "y_true= np.repeat(y_true, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 2. Training\n",
    "### 2.1 Example attempt, standard intialized RF and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "seed = 314159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. this is normal version, that there is no pairing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_pred_list = []\n",
    "# xgb_pred_list = []\n",
    "# y_true_list = []\n",
    "# test_indices_list = []  # Keep track of the test indices in each fold\n",
    "\n",
    "# # Perform k-fold cross-validation:\n",
    "# kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "# for train_index, test_index in kf.split(X_features):\n",
    "#     X_train, X_test = X_features[train_index], X_features[test_index]\n",
    "#     y_train, y_test = y_true[train_index], y_true[test_index]\n",
    "    \n",
    "#     # Train the Random Forest regressor\n",
    "#     rf = RandomForestRegressor(n_estimators=100, random_state=seed)\n",
    "#     rf.fit(X_train, y_train)\n",
    "    \n",
    "#     # Train the XGBoost regressor\n",
    "#     xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=seed)\n",
    "#     xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Make predictions \n",
    "#     rf_pred = rf.predict(X_test)\n",
    "#     xgb_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "#     rf_pred_list.extend(rf_pred)\n",
    "#     xgb_pred_list.extend(xgb_pred)\n",
    "#     y_true_list.extend(y_test)\n",
    "#     test_indices_list.extend(test_index)  # Store the test indices\n",
    "\n",
    "# # Store the predictions and actual values\n",
    "# results_df = pd.DataFrame({\n",
    "#     'test_index': test_indices_list,\n",
    "#     'rf_pred': rf_pred_list,\n",
    "#     'xgb_pred': xgb_pred_list,\n",
    "#     'y_true': y_true_list\n",
    "# })\n",
    "\n",
    "# # Merge the results with the training_set df\n",
    "# training_set = training_set.merge(results_df, left_index=True, right_on='test_index')\n",
    "# training_set.drop('test_index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. pairing, that indicies were selected such that the two that are the same samples always belong to either train or test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_list = []\n",
    "xgb_pred_list = []\n",
    "y_true_list = []\n",
    "test_indices_list = []\n",
    "\n",
    "# Create indices for the original samples (before duplication)\n",
    "original_indices = np.arange(X_features.shape[0] // 2)\n",
    "\n",
    "# Perform k-fold cross-validation on the original indices:\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "for train_index, test_index in kf.split(original_indices):\n",
    "    # Convert original indices to the coupled indices\n",
    "    train_index_coupled = np.concatenate([2*train_index, 2*train_index+1])\n",
    "    test_index_coupled = np.concatenate([2*test_index, 2*test_index+1])\n",
    "    \n",
    "    X_train, X_test = X_features[train_index_coupled], X_features[test_index_coupled]\n",
    "    y_train, y_test = y_true[train_index_coupled], y_true[test_index_coupled]\n",
    "    \n",
    "    # Train the Random Forest regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=seed)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Train the XGBoost regressor\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=seed)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions \n",
    "    rf_pred = rf.predict(X_test)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    rf_pred_list.extend(rf_pred)\n",
    "    xgb_pred_list.extend(xgb_pred)\n",
    "    y_true_list.extend(y_test)\n",
    "    test_indices_list.extend(test_index_coupled)  # Store the coupled test indices\n",
    "\n",
    "# Store the predictions and actual values\n",
    "results_df = pd.DataFrame({\n",
    "    'test_index': test_indices_list,\n",
    "    'rf_pred': rf_pred_list,\n",
    "    'xgb_pred': xgb_pred_list,\n",
    "    'y_true': y_true_list\n",
    "})\n",
    "\n",
    "# Merge the results with the training_set df\n",
    "training_set = training_set.merge(results_df, left_index=True, right_on='test_index')\n",
    "training_set.drop('test_index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mixture 1</th>\n",
       "      <th>Mixture 2</th>\n",
       "      <th>Experimental Values</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.548903</td>\n",
       "      <td>0.566519</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.571137</td>\n",
       "      <td>0.569616</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.675994</td>\n",
       "      <td>0.694503</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.411458</td>\n",
       "      <td>0.692739</td>\n",
       "      <td>0.679863</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.541557</td>\n",
       "      <td>0.560929</td>\n",
       "      <td>0.505208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset  Mixture 1  Mixture 2  Experimental Values   rf_pred  xgb_pred  \\\n",
       "300  Snitz 1          1          2             0.604167  0.548903  0.566519   \n",
       "350  Snitz 1          1          3             0.651042  0.571137  0.569616   \n",
       "600  Snitz 1          1          5             0.505208  0.675994  0.694503   \n",
       "650  Snitz 1          1          6             0.411458  0.692739  0.679863   \n",
       "0    Snitz 1          1          7             0.562500  0.541557  0.560929   \n",
       "\n",
       "       y_true  \n",
       "300  0.604167  \n",
       "350  0.604167  \n",
       "600  0.651042  \n",
       "650  0.651042  \n",
       "0    0.505208  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - R: 0.613\n",
      "Random Forest - RMSE: 0.124\n",
      "\n",
      "XGBoost - R: 0.541\n",
      "XGBoost - RMSE: 0.135\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation and R^2 for Random Forest\n",
    "rf_corr = np.corrcoef(rf_pred_list, y_true_list)[0, 1]\n",
    "rf_rmse = np.sqrt(mean_squared_error(np.array(y_true_list), np.array(rf_pred_list)))\n",
    "\n",
    "print(f\"Random Forest - R: {rf_corr:.3f}\")\n",
    "print(f\"Random Forest - RMSE: {rf_rmse:.3f}\")\n",
    "print()\n",
    "# Calculate the correlation and R^2 for XGBoost\n",
    "xgb_corr = np.corrcoef(xgb_pred_list, y_true_list)[0, 1]\n",
    "xgb_rmse = np.sqrt(mean_squared_error(np.array(y_true_list), np.array(xgb_pred_list)))\n",
    "\n",
    "print(f\"XGBoost - R: {xgb_corr:.3f}\")\n",
    "print(f\"XGBoost - RMSE: {xgb_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result's pretty the same range; which is more reassuring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
