{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Add the ./src folder to the Python module search path\n",
    "sys.path.append(os.path.join(current_dir, '..', 'src'))\n",
    "\n",
    "from utils import *\n",
    "from optimize_symmetric import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Read and inspect data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data'\n",
    "\n",
    "feature_file = 'deepnose_features_UPD.npy'\n",
    "CID_file = 'molecules_train_cid.npy'\n",
    "\n",
    "mixture_file = 'Mixure_Definitions_Training_set.csv'\n",
    "training_task_file = 'TrainingData_mixturedist.csv'\n",
    "\n",
    "# Deepnose features\n",
    "features = np.load(os.path.join(input_path, feature_file))\n",
    "# Training dataframe\n",
    "training_set = pd.read_csv(os.path.join(input_path, training_task_file))\n",
    "\n",
    "# Mapping helper files\n",
    "mixtures_IDs = pd.read_csv(os.path.join(input_path, mixture_file))\n",
    "features_CIDs = np.load(os.path.join(input_path, CID_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out log standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiation\n",
    "# features = np.exp(features)\n",
    "# Standard transform features:\n",
    "epsilon = 1e-8\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "features = scaler.fit_transform(np.log(features + epsilon))\n",
    "\n",
    "# Map CID to 96 dim features:\n",
    "CID2features =  {CID: features[i] for i, CID in enumerate(features_CIDs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- each `x` in `X` contains a two vector tuple `(mixture_1, mixture_2)`, index ordered same way as `training_set`\n",
    "- `method` specifies the ways to create the mixture embeeding from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, num_mixtures, all_pairs_CIDs = format_Xy(training_set,  mixtures_IDs, CID2features, method = 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input pairs to a suitable format for training\n",
    "X_pairs_1 = np.array([(np.concatenate((x1, x2))) for x1, x2 in X])\n",
    "X_pairs_2 = np.array([(np.concatenate((x1, x2))) for x2, x1 in X])\n",
    "\n",
    "y_true = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [get_euclidean_distance(m[0], m[1]) for m in X]\n",
    "similarities = [get_cosine_similarity(m[0], m[1]) for m in X]\n",
    "angles = [get_cosine_angle(m[0], m[1]) for m in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_monos = [ len( set(pair[0]).intersection(set(pair[1]))) for pair in all_pairs_CIDs]\n",
    "diff_monos = [ len( set(pair[0]).difference(set(pair[1]))) for pair in all_pairs_CIDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = training_set['Dataset'].to_numpy()\n",
    "# Returns the uniques in the order of appearance\n",
    "desired_order = training_set['Dataset'].unique().tolist() \n",
    "encoder = OneHotEncoder(categories=[desired_order])\n",
    "data_arr = encoder.fit_transform(datasets.reshape(-1, 1))\n",
    "data_arr = data_arr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add all information above\n",
    "X_features_1 = np.hstack((X_pairs_1, np.array(distances).reshape(500, 1), \n",
    "                        np.array(similarities).reshape(500, 1), \n",
    "                        np.array(angles).reshape(500, 1), \n",
    "                        np.array(shared_monos).reshape(500, 1), \n",
    "                        np.array(diff_monos).reshape(500, 1), \n",
    "                        np.array(num_mixtures), \n",
    "                        data_arr))\n",
    "X_features_2 = np.hstack((X_pairs_2, np.array(distances).reshape(500, 1), \n",
    "                        np.array(similarities).reshape(500, 1), \n",
    "                        np.array(angles).reshape(500, 1), \n",
    "                        np.array(shared_monos).reshape(500, 1), \n",
    "                        np.array(diff_monos).reshape(500, 1), \n",
    "                        np.array(num_mixtures), \n",
    "                        data_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = np.empty((1000, X_features_1.shape[1]), dtype=X_features_1.dtype)\n",
    "X_features[0::2] = X_features_1\n",
    "X_features[1::2] = X_features_2\n",
    "\n",
    "y_true= np.repeat(y_true, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat each row of the training_set dataframe\n",
    "training_set_repeated = training_set.loc[training_set.index.repeat(2)].reset_index(drop=True)\n",
    "\n",
    "# Create a new column for the paired index\n",
    "training_set_repeated['paired_index'] = training_set_repeated.index // 2\n",
    "\n",
    "# Merge the results with the repeated training_set df\n",
    "training_set_final = training_set_repeated\n",
    "\n",
    "# Drop unnecessary columns\n",
    "training_set_final.drop(['paired_index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mixture 1</th>\n",
       "      <th>Mixture 2</th>\n",
       "      <th>Experimental Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.505208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>515</td>\n",
       "      <td>516</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>517</td>\n",
       "      <td>518</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>517</td>\n",
       "      <td>518</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>519</td>\n",
       "      <td>520</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>519</td>\n",
       "      <td>520</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset  Mixture 1  Mixture 2  Experimental Values\n",
       "0    Snitz 1          1          2             0.604167\n",
       "1    Snitz 1          1          2             0.604167\n",
       "2    Snitz 1          1          3             0.651042\n",
       "3    Snitz 1          1          3             0.651042\n",
       "4    Snitz 1          1          5             0.505208\n",
       "..       ...        ...        ...                  ...\n",
       "995  Bushdid        515        516             0.730769\n",
       "996  Bushdid        517        518             0.538462\n",
       "997  Bushdid        517        518             0.538462\n",
       "998  Bushdid        519        520             0.807692\n",
       "999  Bushdid        519        520             0.807692\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 2. Training\n",
    "### 2.1 Example attempt, standard intialized RF and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "seed = 314159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairing, that indicies were selected such that the two that are the same samples always belong to either train or test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_list = []\n",
    "xgb_pred_list = []\n",
    "y_true_list = []\n",
    "test_indices_list = []\n",
    "\n",
    "# Create indices for the original samples (before duplication)\n",
    "original_indices = np.arange(X_features.shape[0] // 2)\n",
    "\n",
    "# Perform k-fold cross-validation on the original indices:\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "for train_index, test_index in kf.split(original_indices):\n",
    "    # Convert original indices to the coupled indices\n",
    "    train_index_coupled = np.concatenate([2*train_index, 2*train_index+1])\n",
    "    test_index_coupled = np.concatenate([2*test_index, 2*test_index+1])\n",
    "    \n",
    "    X_train, X_test = X_features[train_index_coupled], X_features[test_index_coupled]\n",
    "    y_train, y_test = y_true[train_index_coupled], y_true[test_index_coupled]\n",
    "    \n",
    "    # Train the Random Forest regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=seed)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Train the XGBoost regressor\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=seed)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions \n",
    "    rf_pred = rf.predict(X_test)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    rf_pred_list.extend(rf_pred)\n",
    "    xgb_pred_list.extend(xgb_pred)\n",
    "    y_true_list.extend(y_test)\n",
    "    test_indices_list.extend(test_index_coupled)  # Store the coupled test indices\n",
    "\n",
    "# Store the predictions and actual values\n",
    "results_df = pd.DataFrame({\n",
    "    'test_index': test_indices_list,\n",
    "    'rf_pred': rf_pred_list,\n",
    "    'xgb_pred': xgb_pred_list,\n",
    "    'y_true': y_true_list\n",
    "})\n",
    "\n",
    "\n",
    "# Create a temporary index column in training_set_final\n",
    "training_set_final['original_index'] = range(len(training_set_final))\n",
    "\n",
    "# Merge the results with the training_set df\n",
    "training_set_final = training_set_final.merge(results_df, left_on='original_index', right_on='test_index')\n",
    "\n",
    "# Sort by the original index to restore the original order\n",
    "training_set_final = training_set_final.sort_values('original_index').reset_index(drop=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "training_set_final.drop(['original_index', 'test_index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mixture 1</th>\n",
       "      <th>Mixture 2</th>\n",
       "      <th>Experimental Values</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.548903</td>\n",
       "      <td>0.566519</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.571137</td>\n",
       "      <td>0.569616</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.675994</td>\n",
       "      <td>0.694503</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.692739</td>\n",
       "      <td>0.679863</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.541557</td>\n",
       "      <td>0.560929</td>\n",
       "      <td>0.505208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Mixture 1  Mixture 2  Experimental Values   rf_pred  xgb_pred  \\\n",
       "0  Snitz 1          1          2             0.604167  0.548903  0.566519   \n",
       "1  Snitz 1          1          2             0.604167  0.571137  0.569616   \n",
       "2  Snitz 1          1          3             0.651042  0.675994  0.694503   \n",
       "3  Snitz 1          1          3             0.651042  0.692739  0.679863   \n",
       "4  Snitz 1          1          5             0.505208  0.541557  0.560929   \n",
       "\n",
       "     y_true  \n",
       "0  0.604167  \n",
       "1  0.604167  \n",
       "2  0.651042  \n",
       "3  0.651042  \n",
       "4  0.505208  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - R: 0.613\n",
      "Random Forest - RMSE: 0.124\n",
      "\n",
      "XGBoost - R: 0.541\n",
      "XGBoost - RMSE: 0.135\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation and R^2 for Random Forest\n",
    "rf_corr = np.corrcoef(rf_pred_list, y_true_list)[0, 1]\n",
    "rf_rmse = np.sqrt(mean_squared_error(np.array(y_true_list), np.array(rf_pred_list)))\n",
    "\n",
    "print(f\"Random Forest - R: {rf_corr:.3f}\")\n",
    "print(f\"Random Forest - RMSE: {rf_rmse:.3f}\")\n",
    "print()\n",
    "# Calculate the correlation and R^2 for XGBoost\n",
    "xgb_corr = np.corrcoef(xgb_pred_list, y_true_list)[0, 1]\n",
    "xgb_rmse = np.sqrt(mean_squared_error(np.array(y_true_list), np.array(xgb_pred_list)))\n",
    "\n",
    "print(f\"XGBoost - R: {xgb_corr:.3f}\")\n",
    "print(f\"XGBoost - RMSE: {xgb_rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Correlation: 0.6154\n",
      "RMSE: 0.1234\n",
      "\n",
      "XGBoost Results:\n",
      "Correlation: 0.5549\n",
      "RMSE: 0.1323\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to numpy arrays\n",
    "rf_pred_array = np.array(rf_pred_list)\n",
    "xgb_pred_array = np.array(xgb_pred_list)\n",
    "y_true_array = np.array(y_true_list)\n",
    "test_indices_array = np.array(test_indices_list)\n",
    "\n",
    "# Create a sorting index based on test_indices_array\n",
    "sort_idx = np.argsort(test_indices_array)\n",
    "\n",
    "# Sort all arrays based on this index\n",
    "rf_pred_sorted = rf_pred_array[sort_idx]\n",
    "xgb_pred_sorted = xgb_pred_array[sort_idx]\n",
    "y_true_sorted = y_true_array[sort_idx]\n",
    "test_indices_sorted = test_indices_array[sort_idx]\n",
    "\n",
    "# Now, let's pair the sorted arrays\n",
    "rf_pred_paired = rf_pred_sorted.reshape(-1, 2)\n",
    "xgb_pred_paired = xgb_pred_sorted.reshape(-1, 2)\n",
    "y_true_paired = y_true_sorted.reshape(-1, 2)\n",
    "\n",
    "# Average the pairs\n",
    "rf_pred_avg = rf_pred_paired.mean(axis=1)\n",
    "xgb_pred_avg = xgb_pred_paired.mean(axis=1)\n",
    "y_true_avg = y_true_paired.mean(axis=1)\n",
    "\n",
    "# Calculate correlations\n",
    "rf_corr = np.corrcoef(rf_pred_avg, y_true_avg)[0, 1]\n",
    "xgb_corr = np.corrcoef(xgb_pred_avg, y_true_avg)[0, 1]\n",
    "\n",
    "# Calculate RMSE\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_true_avg, rf_pred_avg))\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_true_avg, xgb_pred_avg))\n",
    "\n",
    "# Print results\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Correlation: {rf_corr:.4f}\")\n",
    "print(f\"RMSE: {rf_rmse:.4f}\")\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Correlation: {xgb_corr:.4f}\")\n",
    "print(f\"RMSE: {xgb_rmse:.4f}\")\n",
    "\n",
    "# If you need the original indices for these averaged results:\n",
    "original_indices_avg = test_indices_sorted.reshape(-1, 2).mean(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result's pretty the same range; which is more reassuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = list(range(3))\n",
    "for seed in seeds: \n",
    "    print(f\"Random search for best hyperparams: round {seed +1} \\n\")\n",
    "    rf_best,rbg_best = para_search(seed, X_features, y_true)\n",
    "    print()\n",
    "    rf_out = avg_rf_best(rf_best, X_features, y_true)\n",
    "    print()\n",
    "    rbg_out = avg_xgb_best(rbg_best, X_features, y_true)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
