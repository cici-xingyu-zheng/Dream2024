{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Add the ./src folder to the Python module search path\n",
    "sys.path.append(os.path.join(current_dir, '..', 'src'))\n",
    "\n",
    "from utils import *\n",
    "from optimize_symmetric import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Read and inspect data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../Data'\n",
    "\n",
    "feature_file = 'deepnose_features_UPD.npy'\n",
    "CID_file = 'molecules_train_cid.npy'\n",
    "\n",
    "mixture_file = 'Mixure_Definitions_Training_set.csv'\n",
    "training_task_file = 'TrainingData_mixturedist.csv'\n",
    "\n",
    "# Deepnose features\n",
    "features = np.load(os.path.join(input_path, feature_file))\n",
    "# Training dataframe\n",
    "training_set = pd.read_csv(os.path.join(input_path, training_task_file))\n",
    "\n",
    "# Mapping helper files\n",
    "mixtures_IDs = pd.read_csv(os.path.join(input_path, mixture_file))\n",
    "features_CIDs = np.load(os.path.join(input_path, CID_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out log standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiation\n",
    "# features = np.exp(features)\n",
    "# Standard transform features:\n",
    "epsilon = 1e-8\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "features = scaler.fit_transform(np.log(features + epsilon))\n",
    "\n",
    "# Map CID to 96 dim features:\n",
    "CID2features =  {CID: features[i] for i, CID in enumerate(features_CIDs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- each `x` in `X` contains a two vector tuple `(mixture_1, mixture_2)`, index ordered same way as `training_set`\n",
    "- `method` specifies the ways to create the mixture embeeding from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, num_mixtures, all_pairs_CIDs = format_Xy(training_set,  mixtures_IDs, CID2features, method = 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input pairs to a suitable format for training\n",
    "X_pairs_1 = np.array([(np.concatenate((x1, x2))) for x1, x2 in X])\n",
    "X_pairs_2 = np.array([(np.concatenate((x1, x2))) for x2, x1 in X])\n",
    "\n",
    "y_true = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [get_euclidean_distance(m[0], m[1]) for m in X]\n",
    "similarities = [get_cosine_similarity(m[0], m[1]) for m in X]\n",
    "angles = [get_cosine_angle(m[0], m[1]) for m in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_monos = [ len( set(pair[0]).intersection(set(pair[1]))) for pair in all_pairs_CIDs]\n",
    "diff_monos = [ len( set(pair[0]).difference(set(pair[1]))) for pair in all_pairs_CIDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = training_set['Dataset'].to_numpy()\n",
    "# Returns the uniques in the order of appearance\n",
    "desired_order = training_set['Dataset'].unique().tolist() \n",
    "encoder = OneHotEncoder(categories=[desired_order])\n",
    "data_arr = encoder.fit_transform(datasets.reshape(-1, 1))\n",
    "data_arr = data_arr.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add all information above\n",
    "X_features_1 = np.hstack((X_pairs_1, np.array(distances).reshape(500, 1), \n",
    "                        np.array(similarities).reshape(500, 1), \n",
    "                        np.array(angles).reshape(500, 1), \n",
    "                        np.array(shared_monos).reshape(500, 1), \n",
    "                        np.array(diff_monos).reshape(500, 1), \n",
    "                        np.array(num_mixtures), \n",
    "                        data_arr))\n",
    "X_features_2 = np.hstack((X_pairs_2, np.array(distances).reshape(500, 1), \n",
    "                        np.array(similarities).reshape(500, 1), \n",
    "                        np.array(angles).reshape(500, 1), \n",
    "                        np.array(shared_monos).reshape(500, 1), \n",
    "                        np.array(diff_monos).reshape(500, 1), \n",
    "                        np.array(num_mixtures), \n",
    "                        data_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = np.empty((1000, X_features_1.shape[1]), dtype=X_features_1.dtype)\n",
    "X_features[0::2] = X_features_1\n",
    "X_features[1::2] = X_features_2\n",
    "\n",
    "y_true= np.repeat(y_true, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat each row of the training_set dataframe\n",
    "training_set_repeated = training_set.loc[training_set.index.repeat(2)].reset_index(drop=True)\n",
    "\n",
    "# Create a new column for the paired index\n",
    "training_set_repeated['paired_index'] = training_set_repeated.index // 2\n",
    "\n",
    "# Merge the results with the repeated training_set df\n",
    "training_set_final = training_set_repeated\n",
    "\n",
    "# Drop unnecessary columns\n",
    "training_set_final.drop(['paired_index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mixture 1</th>\n",
       "      <th>Mixture 2</th>\n",
       "      <th>Experimental Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.505208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>515</td>\n",
       "      <td>516</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>517</td>\n",
       "      <td>518</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>517</td>\n",
       "      <td>518</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>519</td>\n",
       "      <td>520</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Bushdid</td>\n",
       "      <td>519</td>\n",
       "      <td>520</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset  Mixture 1  Mixture 2  Experimental Values\n",
       "0    Snitz 1          1          2             0.604167\n",
       "1    Snitz 1          1          2             0.604167\n",
       "2    Snitz 1          1          3             0.651042\n",
       "3    Snitz 1          1          3             0.651042\n",
       "4    Snitz 1          1          5             0.505208\n",
       "..       ...        ...        ...                  ...\n",
       "995  Bushdid        515        516             0.730769\n",
       "996  Bushdid        517        518             0.538462\n",
       "997  Bushdid        517        518             0.538462\n",
       "998  Bushdid        519        520             0.807692\n",
       "999  Bushdid        519        520             0.807692\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 2. Training\n",
    "### 2.1 Example attempt, standard intialized RF and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "# seed = 314159\n",
    "seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = {'n_estimators': 700, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
    "best_xgb = {'subsample': 0.7, 'n_estimators': 600, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairing, that indicies were selected such that the two that are the same samples always belong to either train or test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_list = []\n",
    "xgb_pred_list = []\n",
    "y_true_list = []\n",
    "test_indices_list = []\n",
    "\n",
    "# Create indices for the original samples (before duplication)\n",
    "original_indices = np.arange(X_features.shape[0] // 2)\n",
    "\n",
    "# Perform k-fold cross-validation on the original indices:\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "for train_index, test_index in kf.split(original_indices):\n",
    "    # Convert original indices to the coupled indices\n",
    "    train_index_coupled = np.concatenate([2*train_index, 2*train_index+1])\n",
    "    test_index_coupled = np.concatenate([2*test_index, 2*test_index+1])\n",
    "    \n",
    "    X_train, X_test = X_features[train_index_coupled], X_features[test_index_coupled]\n",
    "    y_train, y_test = y_true[train_index_coupled], y_true[test_index_coupled]\n",
    "    \n",
    "    # Train the Random Forest regressor\n",
    "    # rf = RandomForestRegressor(n_estimators=100, random_state=seed)\n",
    "    rf = RandomForestRegressor(**best_rf, random_state=seed)\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Train the XGBoost regressor\n",
    "    # xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=seed)\n",
    "    xgb_model = xgb.XGBRegressor(**best_xgb, random_state=seed)\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions \n",
    "    rf_pred = rf.predict(X_test)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    rf_pred_list.extend(rf_pred)\n",
    "    xgb_pred_list.extend(xgb_pred)\n",
    "    y_true_list.extend(y_test)\n",
    "    test_indices_list.extend(test_index_coupled)  # Store the coupled test indices\n",
    "\n",
    "# Store the predictions and actual values\n",
    "results_df = pd.DataFrame({\n",
    "    'test_index': test_indices_list,\n",
    "    'rf_pred': rf_pred_list,\n",
    "    'xgb_pred': xgb_pred_list,\n",
    "    'y_true': y_true_list\n",
    "})\n",
    "\n",
    "\n",
    "# Create a temporary index column in training_set_final\n",
    "training_set_final['original_index'] = range(len(training_set_final))\n",
    "\n",
    "# Merge the results with the training_set df\n",
    "training_set_final = training_set_final.merge(results_df, left_on='original_index', right_on='test_index')\n",
    "\n",
    "# Sort by the original index to restore the original order\n",
    "training_set_final = training_set_final.sort_values('original_index').reset_index(drop=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "training_set_final.drop(['original_index', 'test_index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mixture 1</th>\n",
       "      <th>Mixture 2</th>\n",
       "      <th>Experimental Values</th>\n",
       "      <th>rf_pred_x</th>\n",
       "      <th>xgb_pred_x</th>\n",
       "      <th>y_true_x</th>\n",
       "      <th>rf_pred_y</th>\n",
       "      <th>xgb_pred_y</th>\n",
       "      <th>y_true_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.551580</td>\n",
       "      <td>0.556926</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.551771</td>\n",
       "      <td>0.552589</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.546400</td>\n",
       "      <td>0.550507</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.566216</td>\n",
       "      <td>0.553242</td>\n",
       "      <td>0.604167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.688436</td>\n",
       "      <td>0.673092</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.683967</td>\n",
       "      <td>0.675968</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.679467</td>\n",
       "      <td>0.683227</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.678366</td>\n",
       "      <td>0.675755</td>\n",
       "      <td>0.651042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snitz 1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.485055</td>\n",
       "      <td>0.469466</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>0.492298</td>\n",
       "      <td>0.485267</td>\n",
       "      <td>0.505208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Mixture 1  Mixture 2  Experimental Values  rf_pred_x  xgb_pred_x  \\\n",
       "0  Snitz 1          1          2             0.604167   0.551580    0.556926   \n",
       "1  Snitz 1          1          2             0.604167   0.546400    0.550507   \n",
       "2  Snitz 1          1          3             0.651042   0.688436    0.673092   \n",
       "3  Snitz 1          1          3             0.651042   0.679467    0.683227   \n",
       "4  Snitz 1          1          5             0.505208   0.485055    0.469466   \n",
       "\n",
       "   y_true_x  rf_pred_y  xgb_pred_y  y_true_y  \n",
       "0  0.604167   0.551771    0.552589  0.604167  \n",
       "1  0.604167   0.566216    0.553242  0.604167  \n",
       "2  0.651042   0.683967    0.675968  0.651042  \n",
       "3  0.651042   0.678366    0.675755  0.651042  \n",
       "4  0.505208   0.492298    0.485267  0.505208  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - R: 0.631\n",
      "Random Forest - RMSE: 0.123\n",
      "\n",
      "XGBoost - R: 0.6167\n",
      "XGBoost - RMSE: 0.1232\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation and R^2 for Random Forest\n",
    "rf_corr = np.corrcoef(rf_pred_list, y_true_list)[0, 1]\n",
    "rf_rmse = np.sqrt(mean_squared_error(np.array(y_true_list), np.array(rf_pred_list)))\n",
    "\n",
    "print(f\"Random Forest - R: {rf_corr:.3f}\")\n",
    "print(f\"Random Forest - RMSE: {rf_rmse:.3f}\")\n",
    "print()\n",
    "# Calculate the correlation and R^2 for XGBoost\n",
    "xgb_corr = np.corrcoef(xgb_pred_list, y_true_list)[0, 1]\n",
    "xgb_rmse = np.sqrt(mean_squared_error(np.array(y_true_list), np.array(xgb_pred_list)))\n",
    "\n",
    "print(f\"XGBoost - R: {xgb_corr:.4f}\")\n",
    "print(f\"XGBoost - RMSE: {xgb_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Correlation: 0.6312\n",
      "RMSE: 0.1227\n",
      "\n",
      "XGBoost Results:\n",
      "Correlation: 0.6177\n",
      "RMSE: 0.1231\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to numpy arrays\n",
    "rf_pred_array = np.array(rf_pred_list)\n",
    "xgb_pred_array = np.array(xgb_pred_list)\n",
    "y_true_array = np.array(y_true_list)\n",
    "test_indices_array = np.array(test_indices_list)\n",
    "\n",
    "# Create a sorting index based on test_indices_array\n",
    "sort_idx = np.argsort(test_indices_array)\n",
    "\n",
    "# Sort all arrays based on this index\n",
    "rf_pred_sorted = rf_pred_array[sort_idx]\n",
    "xgb_pred_sorted = xgb_pred_array[sort_idx]\n",
    "y_true_sorted = y_true_array[sort_idx]\n",
    "test_indices_sorted = test_indices_array[sort_idx]\n",
    "\n",
    "# Now, let's pair the sorted arrays\n",
    "rf_pred_paired = rf_pred_sorted.reshape(-1, 2)\n",
    "xgb_pred_paired = xgb_pred_sorted.reshape(-1, 2)\n",
    "y_true_paired = y_true_sorted.reshape(-1, 2)\n",
    "\n",
    "# Average the pairs\n",
    "rf_pred_avg = rf_pred_paired.mean(axis=1)\n",
    "xgb_pred_avg = xgb_pred_paired.mean(axis=1)\n",
    "y_true_avg = y_true_paired.mean(axis=1)\n",
    "\n",
    "# Calculate correlations\n",
    "rf_corr = np.corrcoef(rf_pred_avg, y_true_avg)[0, 1]\n",
    "xgb_corr = np.corrcoef(xgb_pred_avg, y_true_avg)[0, 1]\n",
    "\n",
    "# Calculate RMSE\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_true_avg, rf_pred_avg))\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_true_avg, xgb_pred_avg))\n",
    "\n",
    "# Print results\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Correlation: {rf_corr:.4f}\")\n",
    "print(f\"RMSE: {rf_rmse:.4f}\")\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Correlation: {xgb_corr:.4f}\")\n",
    "print(f\"RMSE: {xgb_rmse:.4f}\")\n",
    "\n",
    "# If you need the original indices for these averaged results:\n",
    "original_indices_avg = test_indices_sorted.reshape(-1, 2).mean(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result's pretty the same range; which is more reassuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search for best hyperparams: round 1 \n",
      "\n",
      "Best Random Forest model:\n",
      "Hyperparameters: {'n_estimators': 200, 'min_samples_split': 5, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
      "Correlation: 0.9749787928535641\n",
      "RMSE: 0.04813328596936635\n",
      "\n",
      "Best XGBoost model:\n",
      "Hyperparameters: {'subsample': 0.7, 'n_estimators': 700, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "Correlation: 0.9989799996147316\n",
      "RMSE: 0.008984191964983554\n",
      "\n",
      "RandomForest Average Performance (Non-averaged):\n",
      "R mean: 0.641291744882012\n",
      "R std: 0.01014620867315997\n",
      "RMSE mean: 0.12139377372059498\n",
      "RMSE std: 0.0008219215470271618\n",
      "\n",
      "RandomForest Average Performance (Averaged):\n",
      "R mean: 0.6430024603504805\n",
      "R std: 0.010132916759218572\n",
      "RMSE mean: 0.12125323140738786\n",
      "RMSE std: 0.0008204414232010413\n",
      "\n",
      "RandomForest Overall Performance (Non-averaged):\n",
      "R: 0.6374800825651145\n",
      "RMSE: 0.12198836796386285\n",
      "\n",
      "RandomForest Overall Performance (Averaged):\n",
      "R: 0.6391073263845439\n",
      "RMSE: 0.12185005801189092\n",
      "\n",
      "XGBoost Average Performance (Non-averaged):\n",
      "R mean: 0.6285413886505113\n",
      "R std: 0.00309022539084646\n",
      "RMSE mean: 0.12150654601889195\n",
      "RMSE std: 0.0007815475622710864\n",
      "\n",
      "XGBoost Average Performance (Averaged):\n",
      "R mean: 0.6297057895030422\n",
      "R std: 0.0031404103234219933\n",
      "RMSE mean: 0.12136742463313129\n",
      "RMSE std: 0.0007928990538077034\n",
      "\n",
      "XGBoost Overall Performance (Non-averaged):\n",
      "R: 0.6245872222650176\n",
      "RMSE: 0.12224399249420939\n",
      "\n",
      "XGBoost Overall Performance (Averaged):\n",
      "R: 0.6256754430349002\n",
      "RMSE: 0.12210813191217917\n",
      "\n",
      "Random search for best hyperparams: round 2 \n",
      "\n",
      "Best Random Forest model:\n",
      "Hyperparameters: {'n_estimators': 800, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n",
      "Correlation: 0.9833033912807247\n",
      "RMSE: 0.041691702796748435\n",
      "\n",
      "Best XGBoost model:\n",
      "Hyperparameters: {'subsample': 0.5, 'n_estimators': 800, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.5}\n",
      "Correlation: 0.9979622308675663\n",
      "RMSE: 0.01245895912412245\n",
      "\n",
      "RandomForest Average Performance (Non-averaged):\n",
      "R mean: 0.6443914569165956\n",
      "R std: 0.008026037535666296\n",
      "RMSE mean: 0.12107511655765386\n",
      "RMSE std: 0.0006756141880883378\n",
      "\n",
      "RandomForest Average Performance (Averaged):\n",
      "R mean: 0.6448505553319176\n",
      "R std: 0.008027500944109\n",
      "RMSE mean: 0.1210369098747622\n",
      "RMSE std: 0.0006762684942064581\n",
      "\n",
      "RandomForest Overall Performance (Non-averaged):\n",
      "R: 0.6403762665082626\n",
      "RMSE: 0.1216801962648752\n",
      "\n",
      "RandomForest Overall Performance (Averaged):\n",
      "R: 0.6408182688040646\n",
      "RMSE: 0.12164256326616434\n",
      "\n",
      "XGBoost Average Performance (Non-averaged):\n",
      "R mean: 0.6226684291781016\n",
      "R std: 0.004459175484160402\n",
      "RMSE mean: 0.1223323604504432\n",
      "RMSE std: 0.0008428915993713707\n",
      "\n",
      "XGBoost Average Performance (Averaged):\n",
      "R mean: 0.6243339025269297\n",
      "R std: 0.004434968278147685\n",
      "RMSE mean: 0.12213341171247656\n",
      "RMSE std: 0.0008373991808583444\n",
      "\n",
      "XGBoost Overall Performance (Non-averaged):\n",
      "R: 0.6185137945134195\n",
      "RMSE: 0.12299790176397664\n",
      "\n",
      "XGBoost Overall Performance (Averaged):\n",
      "R: 0.6201040770285005\n",
      "RMSE: 0.12280241672925696\n",
      "\n",
      "Random search for best hyperparams: round 3 \n",
      "\n",
      "Best Random Forest model:\n",
      "Hyperparameters: {'n_estimators': 700, 'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
      "Correlation: 0.9836168042457964\n",
      "RMSE: 0.04150716601365622\n",
      "\n",
      "Best XGBoost model:\n",
      "Hyperparameters: {'subsample': 0.7, 'n_estimators': 600, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.7}\n",
      "Correlation: 0.9982611217816005\n",
      "RMSE: 0.012151269379382835\n",
      "\n",
      "RandomForest Average Performance (Non-averaged):\n",
      "R mean: 0.6443961435231543\n",
      "R std: 0.007818003215878017\n",
      "RMSE mean: 0.12108613082514744\n",
      "RMSE std: 0.0006935124041614737\n",
      "\n",
      "RandomForest Average Performance (Averaged):\n",
      "R mean: 0.644913813261015\n",
      "R std: 0.007824854964657802\n",
      "RMSE mean: 0.12104295553854624\n",
      "RMSE std: 0.0006940742719500034\n",
      "\n",
      "RandomForest Overall Performance (Non-averaged):\n",
      "R: 0.640307510228579\n",
      "RMSE: 0.12168725716953399\n",
      "\n",
      "RandomForest Overall Performance (Averaged):\n",
      "R: 0.6408073063503101\n",
      "RMSE: 0.12164470565890317\n",
      "\n",
      "XGBoost Average Performance (Non-averaged):\n",
      "R mean: 0.6233616603336992\n",
      "R std: 0.005971806881486382\n",
      "RMSE mean: 0.1221015071009682\n",
      "RMSE std: 0.00046669668638438065\n",
      "\n",
      "XGBoost Average Performance (Averaged):\n",
      "R mean: 0.6244563967646426\n",
      "R std: 0.006038862631735378\n",
      "RMSE mean: 0.12196562683058917\n",
      "RMSE std: 0.00047003078619324736\n",
      "\n",
      "XGBoost Overall Performance (Non-averaged):\n",
      "R: 0.6197148585889022\n",
      "RMSE: 0.12286443745641887\n",
      "\n",
      "XGBoost Overall Performance (Averaged):\n",
      "R: 0.6207577646327457\n",
      "RMSE: 0.12273077497355808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seeds = list(range(3))\n",
    "for seed in seeds: \n",
    "    print(f\"Random search for best hyperparams: round {seed +1} \\n\")\n",
    "    rf_best,rbg_best = para_search(seed, X_features, y_true)\n",
    "    print()\n",
    "    rf_out = avg_rf_best(rf_best, X_features, y_true)\n",
    "    print()\n",
    "    rbg_out = avg_xgb_best(rbg_best, X_features, y_true)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
